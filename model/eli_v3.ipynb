{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bshort95/final_project/blob/main/model/eli_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5omSoJ0bhKd9",
        "outputId": "5ec55233-d38f-4f6d-c264-16d3671b3978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torchmetrics\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7tQeBiY5f7kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d358104-d7bf-46cc-c7a7-85bcdb2a2d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizerFast\n",
        "import torch\n",
        "from torchmetrics import F1Score\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kmQKUsmRga9L"
      },
      "outputs": [],
      "source": [
        "# big data set\n",
        "\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/bshort95/final_project/main/data.csv')\n",
        "\n",
        "# condensed data set\n",
        "df = pd.read_csv('https://github.com/bshort95/final_project/raw/main/datav3.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIc72jm3gmbf",
        "outputId": "ff5ff24d-a3bb-4d30-8614-8129f653064d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'S_perks', 'E_degree', 'E_Misc_Info', 'E_Soft_Skill', 'S_Years_Experince', 'S_Company_Name', 'S_resp', 'E_location', 'E_Important_Dates', 'S_Hard_Skill', 'E_resp', 'S_Important_Dates', 'E_Years_Experince', 'E_perks', 'S_degree', 'S_Soft_Skill', 'S_location', 'E_Company_Name', 'O', 'S_Misc_Info', 'E_Hard_Skill'}\n"
          ]
        }
      ],
      "source": [
        "labels = [i.split() for i in df['mask'].values.tolist()]\n",
        "\n",
        "unique_labels = set()\n",
        "\n",
        "for lb in labels:\n",
        "  [unique_labels.add(i) for i in lb if i not in unique_labels]\n",
        " \n",
        "print(unique_labels)\n",
        "\n",
        "# Map each label into its id representation and vice versa\n",
        "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
        "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
        "\n",
        "label_all_tokens = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mAtPmOK4joyu"
      },
      "outputs": [],
      "source": [
        "def align_label(texts, labels):\n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(labels_to_ids[labels[word_idx]])\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "class DataSequence(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        lb = [i.split() for i in df['labels'].values.tolist()]\n",
        "        txt = df['text'].values.tolist()\n",
        "        self.texts = [tokenizer(str(i),\n",
        "                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n",
        "        self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_data(self, idx):\n",
        "\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "\n",
        "        return torch.LongTensor(self.labels[idx])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_data = self.get_batch_data(idx)\n",
        "        batch_labels = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6IlDuvJ4j9ly"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "df = df.rename(columns={'mask': 'labels'})\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                            [int(.8 * len(df)), int(.9 * len(df))])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F2BGSTbFkD9m"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from transformers import BertForTokenClassification\n",
        "\n",
        "class BertModel1(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(BertModel1, self).__init__()\n",
        "\n",
        "        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n",
        "\n",
        "    def forward(self, input_id, mask, label):\n",
        "\n",
        "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t5B9dyo7av5m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFK_CA3SkLIG",
        "outputId": "178f09af-7d8e-475a-a5cc-fcb736eae75a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 144/144 [00:11<00:00, 12.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Loss:  2.335 | micro-f1:  0.553 | Val_Loss:  1.345 | micro-f1:  0.962\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 2 | Loss:  1.117 | micro-f1:  0.811 | Val_Loss:  0.895 | micro-f1:  0.765\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.53it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 3 | Loss:  1.015 | micro-f1:  0.811 | Val_Loss:  0.846 | micro-f1:  0.923\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 4 | Loss:  0.962 | micro-f1:  0.811 | Val_Loss:  0.814 | micro-f1:  0.555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 5 | Loss:  0.934 | micro-f1:  0.811 | Val_Loss:  0.783 | micro-f1:  0.721\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 6 | Loss:  0.905 | micro-f1:  0.811 | Val_Loss:  0.765 | micro-f1:  0.897\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.53it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 7 | Loss:  0.890 | micro-f1:  0.811 | Val_Loss:  0.750 | micro-f1:  0.790\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 8 | Loss:  0.878 | micro-f1:  0.811 | Val_Loss:  0.736 | micro-f1:  0.710\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 9 | Loss:  0.863 | micro-f1:  0.811 | Val_Loss:  0.726 | micro-f1:  0.741\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 10 | Loss:  0.853 | micro-f1:  0.812 | Val_Loss:  0.721 | micro-f1:  0.585\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 11 | Loss:  0.841 | micro-f1:  0.812 | Val_Loss:  0.709 | micro-f1:  0.948\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 12 | Loss:  0.820 | micro-f1:  0.812 | Val_Loss:  0.703 | micro-f1:  0.949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 13 | Loss:  0.812 | micro-f1:  0.812 | Val_Loss:  0.683 | micro-f1:  0.792\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 14 | Loss:  0.801 | micro-f1:  0.812 | Val_Loss:  0.680 | micro-f1:  0.801\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 15 | Loss:  0.790 | micro-f1:  0.812 | Val_Loss:  0.663 | micro-f1:  0.618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.53it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 16 | Loss:  0.776 | micro-f1:  0.812 | Val_Loss:  0.657 | micro-f1:  0.928\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 17 | Loss:  0.766 | micro-f1:  0.812 | Val_Loss:  0.655 | micro-f1:  0.872\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 18 | Loss:  0.751 | micro-f1:  0.812 | Val_Loss:  0.646 | micro-f1:  0.958\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 19 | Loss:  0.745 | micro-f1:  0.813 | Val_Loss:  0.631 | micro-f1:  0.802\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 20 | Loss:  0.734 | micro-f1:  0.813 | Val_Loss:  0.627 | micro-f1:  0.845\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 21 | Loss:  0.729 | micro-f1:  0.813 | Val_Loss:  0.621 | micro-f1:  0.938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 22 | Loss:  0.718 | micro-f1:  0.814 | Val_Loss:  0.613 | micro-f1:  0.761\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 23 | Loss:  0.711 | micro-f1:  0.814 | Val_Loss:  0.605 | micro-f1:  0.770\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 24 | Loss:  0.706 | micro-f1:  0.814 | Val_Loss:  0.605 | micro-f1:  0.850\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.54it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 25 | Loss:  0.696 | micro-f1:  0.816 | Val_Loss:  0.601 | micro-f1:  0.893\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 26 | Loss:  0.691 | micro-f1:  0.815 | Val_Loss:  0.595 | micro-f1:  0.773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 27 | Loss:  0.684 | micro-f1:  0.815 | Val_Loss:  0.599 | micro-f1:  0.814\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 28 | Loss:  0.680 | micro-f1:  0.816 | Val_Loss:  0.577 | micro-f1:  0.889\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 29 | Loss:  0.669 | micro-f1:  0.817 | Val_Loss:  0.579 | micro-f1:  0.762\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 30 | Loss:  0.666 | micro-f1:  0.817 | Val_Loss:  0.579 | micro-f1:  0.768\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 31 | Loss:  0.657 | micro-f1:  0.818 | Val_Loss:  0.591 | micro-f1:  0.765\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 32 | Loss:  0.655 | micro-f1:  0.818 | Val_Loss:  0.579 | micro-f1:  0.941\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 33 | Loss:  0.649 | micro-f1:  0.819 | Val_Loss:  0.563 | micro-f1:  0.810\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 34 | Loss:  0.647 | micro-f1:  0.820 | Val_Loss:  0.560 | micro-f1:  0.724\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 35 | Loss:  0.640 | micro-f1:  0.820 | Val_Loss:  0.557 | micro-f1:  0.686\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 36 | Loss:  0.635 | micro-f1:  0.819 | Val_Loss:  0.559 | micro-f1:  0.887\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 37 | Loss:  0.631 | micro-f1:  0.819 | Val_Loss:  0.558 | micro-f1:  0.817\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 38 | Loss:  0.629 | micro-f1:  0.819 | Val_Loss:  0.547 | micro-f1:  0.916\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.53it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 39 | Loss:  0.623 | micro-f1:  0.821 | Val_Loss:  0.552 | micro-f1:  0.815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.53it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 40 | Loss:  0.616 | micro-f1:  0.821 | Val_Loss:  0.558 | micro-f1:  0.695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 41 | Loss:  0.615 | micro-f1:  0.822 | Val_Loss:  0.553 | micro-f1:  0.530\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 42 | Loss:  0.613 | micro-f1:  0.821 | Val_Loss:  0.547 | micro-f1:  0.742\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 43 | Loss:  0.609 | micro-f1:  0.822 | Val_Loss:  0.542 | micro-f1:  0.842\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 44 | Loss:  0.604 | micro-f1:  0.821 | Val_Loss:  0.539 | micro-f1:  0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 45 | Loss:  0.598 | micro-f1:  0.823 | Val_Loss:  0.543 | micro-f1:  0.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 46 | Loss:  0.598 | micro-f1:  0.823 | Val_Loss:  0.545 | micro-f1:  0.879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 47 | Loss:  0.597 | micro-f1:  0.823 | Val_Loss:  0.540 | micro-f1:  0.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 48 | Loss:  0.593 | micro-f1:  0.822 | Val_Loss:  0.540 | micro-f1:  0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 49 | Loss:  0.589 | micro-f1:  0.824 | Val_Loss:  0.531 | micro-f1:  0.912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 50 | Loss:  0.587 | micro-f1:  0.824 | Val_Loss:  0.540 | micro-f1:  0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 51 | Loss:  0.585 | micro-f1:  0.823 | Val_Loss:  0.533 | micro-f1:  0.771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 52 | Loss:  0.580 | micro-f1:  0.824 | Val_Loss:  0.534 | micro-f1:  0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 53 | Loss:  0.579 | micro-f1:  0.824 | Val_Loss:  0.533 | micro-f1:  0.811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 54 | Loss:  0.573 | micro-f1:  0.824 | Val_Loss:  0.538 | micro-f1:  0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 55 | Loss:  0.573 | micro-f1:  0.824 | Val_Loss:  0.535 | micro-f1:  0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 56 | Loss:  0.572 | micro-f1:  0.825 | Val_Loss:  0.528 | micro-f1:  0.778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 57 | Loss:  0.567 | micro-f1:  0.827 | Val_Loss:  0.533 | micro-f1:  0.793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 58 | Loss:  0.564 | micro-f1:  0.825 | Val_Loss:  0.529 | micro-f1:  0.541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 59 | Loss:  0.562 | micro-f1:  0.826 | Val_Loss:  0.534 | micro-f1:  0.670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 60 | Loss:  0.561 | micro-f1:  0.825 | Val_Loss:  0.525 | micro-f1:  0.802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 61 | Loss:  0.556 | micro-f1:  0.827 | Val_Loss:  0.530 | micro-f1:  0.690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 62 | Loss:  0.554 | micro-f1:  0.828 | Val_Loss:  0.528 | micro-f1:  0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 63 | Loss:  0.555 | micro-f1:  0.828 | Val_Loss:  0.531 | micro-f1:  0.599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 64 | Loss:  0.549 | micro-f1:  0.827 | Val_Loss:  0.528 | micro-f1:  0.791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 65 | Loss:  0.550 | micro-f1:  0.827 | Val_Loss:  0.521 | micro-f1:  0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 66 | Loss:  0.549 | micro-f1:  0.827 | Val_Loss:  0.527 | micro-f1:  0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 67 | Loss:  0.544 | micro-f1:  0.829 | Val_Loss:  0.522 | micro-f1:  0.554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 68 | Loss:  0.541 | micro-f1:  0.829 | Val_Loss:  0.520 | micro-f1:  0.803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 69 | Loss:  0.542 | micro-f1:  0.827 | Val_Loss:  0.528 | micro-f1:  0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 70 | Loss:  0.539 | micro-f1:  0.827 | Val_Loss:  0.523 | micro-f1:  0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 71 | Loss:  0.537 | micro-f1:  0.829 | Val_Loss:  0.517 | micro-f1:  0.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 72 | Loss:  0.534 | micro-f1:  0.830 | Val_Loss:  0.513 | micro-f1:  0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 73 | Loss:  0.537 | micro-f1:  0.830 | Val_Loss:  0.508 | micro-f1:  0.928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 74 | Loss:  0.532 | micro-f1:  0.828 | Val_Loss:  0.514 | micro-f1:  0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 144/144 [00:10<00:00, 13.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 75 | Loss:  0.531 | micro-f1:  0.829 | Val_Loss:  0.516 | micro-f1:  0.882\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "def train_loop(model, df_train, df_val):\n",
        "\n",
        "    train_dataset = DataSequence(df_train)\n",
        "    val_dataset = DataSequence(df_val)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    best_acc = 0\n",
        "    best_loss = 1000\n",
        "\n",
        "    for epoch_num in range(EPOCHS):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            \n",
        "            loss, logits = model(input_id, mask, train_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "              temp = {}\n",
        "\n",
        "              logits_clean = logits[i][train_label[i] != -100]\n",
        "              label_clean = train_label[i][train_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              labels = set(predictions.tolist() + label_clean.tolist())\n",
        "              \n",
        "              f1 = F1Score(task = \"multiclass\", num_classes=(len(unique_labels))).to(device)\n",
        "              f1_score = f1(predictions.to(device), label_clean.to(device))\n",
        "\n",
        "              total_acc_train += f1_score\n",
        "              total_loss_train += loss.item()\n",
        "                      \n",
        "\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        for val_data, val_label in val_dataloader:\n",
        "\n",
        "            val_label = val_label.to(device)\n",
        "            mask = val_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = val_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            loss, logits = model(input_id, mask, val_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "              temp = {}\n",
        "\n",
        "              logits_clean = logits[i][train_label[i] != -100]\n",
        "              label_clean = train_label[i][train_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "                         \n",
        "              f1 = F1Score(task = \"multiclass\", num_classes=(len(unique_labels))).to(device)\n",
        "              f1_score = f1(predictions.to(device), label_clean.to(device))\n",
        "\n",
        "              \n",
        "              total_acc_val += f1_score\n",
        "              total_loss_val += loss.item()\n",
        "        val_accuracy = total_acc_val / len(df_val)\n",
        "        val_loss = total_loss_val / len(df_val)\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | micro-f1: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | micro-f1: {total_acc_val / len(df_val): .3f}')\n",
        "\n",
        "LEARNING_RATE = 1e-6\n",
        "EPOCHS = 75\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "model = BertModel1()\n",
        "train_loop(model, df_train, df_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AYg2K1vBOK8s"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "torch.save(model,\"/content/gdrive/MyDrive/models/srproj/model.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_LqUr2l2f9eU"
      },
      "outputs": [],
      "source": [
        "pickled_model = torch.load(\"/content/gdrive/MyDrive/models/srproj/model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VUlr3K7JoSev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b835ab17-5da7-45ae-c007-22fb694e38d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.795\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, df_test):\n",
        "\n",
        "    test_dataset = DataSequence(df_test)\n",
        "\n",
        "    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0.0\n",
        "\n",
        "    for test_data, test_label in test_dataloader:\n",
        "\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_data['attention_mask'].squeeze(1).to(device)\n",
        "\n",
        "            input_id = test_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            loss, logits = model(input_id, mask, test_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "              temp = {}\n",
        "\n",
        "              logits_clean = logits[i][test_label[i] != -100]\n",
        "              label_clean = test_label[i][test_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              labels = set(predictions.tolist() + label_clean.tolist())\n",
        "              \n",
        "              for j in range(len(labels)):\n",
        "                temp[list(labels)[j]] = j\n",
        "\n",
        "              temp_pred = []\n",
        "              temp_label = []\n",
        "              for pred in predictions.tolist():\n",
        "                temp_pred.append(temp[pred])\n",
        "              for pred in label_clean.tolist():\n",
        "                temp_label.append(temp[pred])\n",
        "            \n",
        "\n",
        "              temp_pred = torch.tensor(temp_pred)\n",
        "              temp_label = torch.tensor(temp_label)\n",
        "              \n",
        "              # if len(labels) == 1:\n",
        "              #   f1 = F1Score(task = \"binary\", num_classes=(len(labels)), multiclass=False)\n",
        "              # else:\n",
        "              #   f1 = F1Score(task = \"multiclass\", num_classes=(len(labels)))\n",
        "              f1 = F1Score(task = \"multiclass\", num_classes=(len(unique_labels))).to(device)\n",
        "              f1_score = f1(predictions.to(device), label_clean.to(device))\n",
        "\n",
        "              # acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_test += f1_score\n",
        "\n",
        "        # val_accuracy = total_acc_val / len(df_val)\n",
        "        # val_loss = total_loss_val / len(df_val)\n",
        "\n",
        "    val_accuracy = total_acc_test / len(df_test)\n",
        "    print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n",
        "\n",
        "\n",
        "evaluate(pickled_model, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h2f93yMlLjPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95b7800-1e12-4277-d32b-065c16dc341b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thank you for applying to a job at eClerx US. Please note that if hired, eClerx LLC will require you provide your Covid-19 vaccination status on your first day of employment. Vaccination information allows the company to plan health and safety protocols and\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def align_word_ids(texts):\n",
        "  \n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(1)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(1 if label_all_tokens else -100)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "\n",
        "def evaluate_one_text(model, sentence):\n",
        "\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    mask = text['attention_mask'].to(device)\n",
        "    input_id = text['input_ids'].to(device)\n",
        "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
        "\n",
        "    logits = model(input_id, mask, None)\n",
        "    logits_clean = logits[0][label_ids != -100]\n",
        "\n",
        "    predictions = logits_clean.argmax(dim=1).tolist()\n",
        "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
        "    print(sentence)\n",
        "    print(prediction_label)\n",
        "            \n",
        "evaluate_one_text(pickled_model, 'Thank you for applying to a job at eClerx US. Please note that if hired, eClerx LLC will require you provide your Covid-19 vaccination status on your first day of employment. Vaccination information allows the company to plan health and safety protocols and')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPp9ke1t0nCxKweCaXHipr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}